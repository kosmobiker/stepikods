{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost\n",
    "\n",
    "Выделяют три группы параметров:\n",
    "- Общие параметры, отвечающие за базовый алгоритм для бустинга и распараллеливание.\n",
    "- Параметры выбранного базового алгоритма.\n",
    "- Параметры обучения, отвечающие за функцию потерь и метрику качества на валидации.\n",
    "\n",
    "**1. Общие параметры:**\n",
    "- booster [default=gbtree] - тип базового алгоритма для бустинга: дерево решений gbtree или линейная модель gblinear. \n",
    "- silent [default=0] - выдавать (silent=0) или нет (silent=1) сообщения по ходу работы алгоритма.\n",
    "- nthread [default to maximum number of threads available if not set] - число потоков доступных для параллельной работы xgboost.\n",
    "\n",
    "**2. Параметры базового алгоритма:**\n",
    "\n",
    "**2.1. Дерево решений:**\n",
    "- eta [default=0.3] - темп обучения, перед добавлением дерева в композицию оно умножается на eta. Используется для предотвращения переобучения за счёт \"сокращения\" весов базовых алгоритмов, делая модель более консервативной. Чем меньше eta, тем больше нужно итераций num_boost_round для обучения модели с хорошим качеством. Диапазон: [0, 1]\n",
    "- gamma [default=0] - минимальное снижение значения функции потерь, необходимое для дальнейшего разбиения вершины дерева. Большие значения gamma > 0 приводят к более консервативным моделям. Диапазон: [0, $\\infty$).\n",
    "- max_depth [default=6] - максимальная глубина дерева. Диапазон: [1, $\\infty$). \n",
    "- min_child_weight [default=1] - минимальное необходимое (взвешенное) число примеров в каждой вершине. Чем больше, тем более консервативна итоговая модель. Диапазон: [0, $\\infty$).\n",
    "- max_delta_step [default=0] - обычно равен нулю. Положительные значения используются при несбалансированных классах для ускорения сходимости. Диапазон [0, $\\infty$).\n",
    "- subsample [default=1] - доля выборки, используемая для обучения каждого дерева. Если subsample < 1, то выбирается случайная подвыборка, что помогает в борьбе с переобучением. Диапазон: (0, 1]\n",
    "- colsample_bytree [default=1] - доля признаков, используемая для обучения каждого дерева. Диапазон: (0, 1]\n",
    "- lambda [default=1] - коэффициент перед $L_2$-регуляризатором в функции потерь.\n",
    "- alpha [default=0] - коэффициент перед $L_1$-регуляризатором в функции потерь.\n",
    "\n",
    "**2.2. Линейная модель:**\n",
    "- lambda [default=0] - коэффициент перед $L_2$-регуляризатором вектора весов в функции потерь.\n",
    "- alpha [default=0] - коэффициент перед $L_1$-регуляризатором вектора весов в функции потерь.\n",
    "- lambda_bias [default=0] - коэффициент перед $L_2$-регуляризатором смещения (свободного члена) в функции потерь.\n",
    "\n",
    "**3. Параметры задачи обучения:**\n",
    "- objective [default=reg:linear] - используемая при обучении функция потерь:\n",
    "    - \"reg:linear\" – линейная регрессия.\n",
    "    - \"reg:logistic\" – логистическая регрессия.\n",
    "    - \"binary:logistic\" – логистическая регрессия для бинарной классификации, на выходе - вероятность.\n",
    "    - \"binary:logitraw\" – то же самое, но на выходе - значение до его преобразования логистической функцией.\n",
    "    - \"count:poisson\" – регрессия Пуассона (используется для оценки числа каких-то событий, счётный признак), на выходе - матожидания распределения Пуассона. В этом случае max_delta_step автоматически устанавливается равным 0.7.\n",
    "    - \"multi:softmax\" – обобщение логистической регрессии на многоклассовый случай. При этом нужно задать параметр num_class.\n",
    "    - \"multi:softprob\" – то же самое, но на выходе - вектор размера ndata * nclass, который можно преобразовать в матрицу, содержащую вероятности отнесения данного объекта к данному классу.\n",
    "    - \"rank:pairwise\" – используется для задач ранжирования.\n",
    "- base_score [default=0.5] - инициализация значения модели для всех примеров, глобальное смещение.\n",
    "- eval_metric [default according to objective] - метрика качества на валидационной выборке (по умолчанию соответствует функции потерь: rmse - для регрессии, error - для классификации, mean average precision - для ранжирования). Выбрать можно одну из следующих метрик:\n",
    "    - \"rmse\": root mean square error.\n",
    "    - \"logloss\": минус логарифм правдоподобия.\n",
    "    - \"error\": доля ошибок для бинарной классификации.\n",
    "    - \"merror\": то же самое для многоклассовой классификации.\n",
    "    - \"mlogloss\": logloss для многоклассовой классификации.\n",
    "    - \"auc\": AUC.\n",
    "    - \"ndcg\": Normalized Discounted Cumulative Gain.\n",
    "    - \"map\": Mean average precision.\n",
    "    - \"ndcg@n\",”map@n”: здесь n - целое число, первые n позиций в списке не учитываются.\n",
    "    - \"ndcg-\",”map-”,”ndcg@n-”,”map@n-”: списку из всех положительных примеров будет присвоено значение 0 (вместо 1).\n",
    "- seed [default=0] - для воспроизводимости \"случайности\".\n",
    "\n",
    "**Параметры в xgboost.train**:\n",
    "- params (dict) – параметры, описанные выше.\n",
    "- dtrain (DMatrix) – обучающая выборка.\n",
    "- num_boost_round (int) – число итераций бустинга.\n",
    "- evals (list) – список для оценки качества во время обучения.\n",
    "- obj (function) – собственная функция потерь.\n",
    "- feval (function) – собственная функция для оценки качества.\n",
    "- maximize (bool) – нужно ли максимизировать feval.\n",
    "- early_stopping_rounds (int) – активирует early stopping. Ошибка на валидации должна уменьшаться каждые early_stopping_rounds итераций для продолжения обучения. Список evals должен быть не пуст. Возвращается модель с последней итерации. Если произошел ранний останов, то модель будет содержать поля: bst.best_score и bst.best_iteration.\n",
    "- evals_result (dict) – результаты оценки качества.\n",
    "- verbose_eval (bool) – вывод значения метрики качества на каждой итерации бустинга.\n",
    "- learning_rates (list or function) – коэффициент скорости обучения для каждой итерации - list l: eta = l[boosting round] - function f: eta = f(boosting round, num_boost_round).\n",
    "- xgb_model (file name of stored xgb model or ‘Booster’ instance) – возможность продолжить обучения имеющейся модели XGB.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## sklearn.ensemble.GradientBoostingClassifier\n",
    "- loss [default=\"deviance\"] - оптимизируемая функция потерь.  Одна из {\"deviance\", \"exponential\"}. Первая соответствует логистической регрессии и возвращает вероятности, вторая - AdaBoost.\n",
    "- learning_rate [default=0.1] - темп обучения, аналогично eta для XGBoost.\n",
    "- n_estimators [default=100] - число итераций градиентного бустинга.\n",
    "- max_depth [default=3] - аналогично max_depth для XGBoost.\n",
    "- min_samples_split [default=2] - минимальное число примеров, необходимое для разветвления в данной вершине,  аналогично min_child_weight для XGBoost.\n",
    "- min_samples_leaf [default=1] - минимальное число примеров в листе.\n",
    "- min_weight_fraction_leaf [default=0.0] - минимальное взвешенное число примеров в листе.\n",
    "- subsample [default=1.0] - аналогично subsample для XGBoost.\n",
    "- max_features (int, float, string or None) [default=None] - число (или доля) признаков, используемых при разбиении вершины.\n",
    "    - \"auto\", тогда max_features=sqrt(n_features).\n",
    "    - \"sqrt\", тогда max_features=sqrt(n_features).\n",
    "    - \"log2\", тогда max_features=log2(n_features).\n",
    "    - None, тогда max_features=n_features.\n",
    "- max_leaf_nodes [default=None]\n",
    "- init (BaseEstimator or None) [default=None] - алгоритм для начальных предсказаний.\n",
    "- verbose [default=0] - аналогично silent для XGBoost.\n",
    "- warm_start [default=False] - если True, используется ансамбль с предыдущего вызова fit, новые алгоритмы добавляются к нему, иначе строится новый алгоритм."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Что можно улучшить?\n",
    "1. Снижение разброса\n",
    "\n",
    "- Для уменьшения сложности модели можно:\n",
    "\n",
    "    - использовать меньше признаков (например, отбор)\n",
    "    - использовать больше объектов (например, искусственно созданных)\n",
    "    - увеличить регуляризацию\n",
    "\n",
    "- В случае XGBoost можно:\n",
    "\n",
    "    - уменьшать максимальную глубину деревьев(max_depth)\n",
    "    - увеличивать значение параметра min_child_weight\n",
    "    - увеличивать значение параметра gamma\n",
    "    - добавлять больше \"случайности\" за счет параметров subsample и colsample_bytree\n",
    "    - увеличивать значение параметров регуляризации lambda и alpha\n",
    "\n",
    "2. Снижение смещения\n",
    "\n",
    "- Если модель слишком простая, можно:\n",
    "\n",
    "    - добавлять больше признаков (например, изобретать их),\n",
    "    - усложнять модель\n",
    "    - уменьшать регуляризацию\n",
    "\n",
    "- В случае XGBoost можно:\n",
    "\n",
    "    - увеличивать максимальную глубину деревьев(max_depth)\n",
    "    - уменьшать значение параметра min_child_weight\n",
    "    - уменьшать значение параметра gamma\n",
    "    - уменьшать значение параметров регуляризации lambda и alpha\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Общие советы\n",
    "\n",
    "Есть несколько общих советов по работе с несбалансированными выборками:\n",
    "\n",
    "   - собрать больше данных\n",
    "   - использовать метрики, нечувствительные к дисбалансу классов (F1, ROC AUC)\n",
    "   - oversampling/undersampling - брать больше объектов мало представленного класса, и мало - частого класса\n",
    "   - создать искусственные объекты, похожие на объекты редкого класса (например, алгоритмом SMOTE)\n",
    "\n",
    "С XGBoost можно:\n",
    "\n",
    "   - следить за тем, чтобы параметр min_child_weight был мал, хотя по умолчанию он и так равен 1.\n",
    "   - задать ббольше веса некоторым объектам при инициализации DMatrix\n",
    "   - контролировать отшошение числа представителей разных классов с помощью параметра set_pos_weight\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "pd.set_option('display.max.columns', 100)\n",
    "from sklearn.model_selection import train_test_split, cross_val_score, StratifiedKFold\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import warnings\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.read_csv('../data/bank.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>age</th>\n",
       "      <th>job</th>\n",
       "      <th>marital</th>\n",
       "      <th>education</th>\n",
       "      <th>default</th>\n",
       "      <th>balance</th>\n",
       "      <th>housing</th>\n",
       "      <th>loan</th>\n",
       "      <th>contact</th>\n",
       "      <th>day</th>\n",
       "      <th>month</th>\n",
       "      <th>duration</th>\n",
       "      <th>campaign</th>\n",
       "      <th>pdays</th>\n",
       "      <th>previous</th>\n",
       "      <th>poutcome</th>\n",
       "      <th>y</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>30</td>\n",
       "      <td>unemployed</td>\n",
       "      <td>married</td>\n",
       "      <td>primary</td>\n",
       "      <td>no</td>\n",
       "      <td>1787</td>\n",
       "      <td>no</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>19</td>\n",
       "      <td>oct</td>\n",
       "      <td>79</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>33</td>\n",
       "      <td>services</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>4789</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>cellular</td>\n",
       "      <td>11</td>\n",
       "      <td>may</td>\n",
       "      <td>220</td>\n",
       "      <td>1</td>\n",
       "      <td>339</td>\n",
       "      <td>4</td>\n",
       "      <td>failure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>35</td>\n",
       "      <td>management</td>\n",
       "      <td>single</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1350</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>cellular</td>\n",
       "      <td>16</td>\n",
       "      <td>apr</td>\n",
       "      <td>185</td>\n",
       "      <td>1</td>\n",
       "      <td>330</td>\n",
       "      <td>1</td>\n",
       "      <td>failure</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>30</td>\n",
       "      <td>management</td>\n",
       "      <td>married</td>\n",
       "      <td>tertiary</td>\n",
       "      <td>no</td>\n",
       "      <td>1476</td>\n",
       "      <td>yes</td>\n",
       "      <td>yes</td>\n",
       "      <td>unknown</td>\n",
       "      <td>3</td>\n",
       "      <td>jun</td>\n",
       "      <td>199</td>\n",
       "      <td>4</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>59</td>\n",
       "      <td>blue-collar</td>\n",
       "      <td>married</td>\n",
       "      <td>secondary</td>\n",
       "      <td>no</td>\n",
       "      <td>0</td>\n",
       "      <td>yes</td>\n",
       "      <td>no</td>\n",
       "      <td>unknown</td>\n",
       "      <td>5</td>\n",
       "      <td>may</td>\n",
       "      <td>226</td>\n",
       "      <td>1</td>\n",
       "      <td>-1</td>\n",
       "      <td>0</td>\n",
       "      <td>unknown</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   age          job  marital  education default  balance housing loan  \\\n",
       "0   30   unemployed  married    primary      no     1787      no   no   \n",
       "1   33     services  married  secondary      no     4789     yes  yes   \n",
       "2   35   management   single   tertiary      no     1350     yes   no   \n",
       "3   30   management  married   tertiary      no     1476     yes  yes   \n",
       "4   59  blue-collar  married  secondary      no        0     yes   no   \n",
       "\n",
       "    contact  day month  duration  campaign  pdays  previous poutcome  y  \n",
       "0  cellular   19   oct        79         1     -1         0  unknown  0  \n",
       "1  cellular   11   may       220         1    339         4  failure  0  \n",
       "2  cellular   16   apr       185         1    330         1  failure  0  \n",
       "3   unknown    3   jun       199         4     -1         0  unknown  0  \n",
       "4   unknown    5   may       226         1     -1         0  unknown  0  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 4521 entries, 0 to 4520\n",
      "Data columns (total 17 columns):\n",
      " #   Column     Non-Null Count  Dtype \n",
      "---  ------     --------------  ----- \n",
      " 0   age        4521 non-null   int64 \n",
      " 1   job        4521 non-null   object\n",
      " 2   marital    4521 non-null   object\n",
      " 3   education  4521 non-null   object\n",
      " 4   default    4521 non-null   object\n",
      " 5   balance    4521 non-null   int64 \n",
      " 6   housing    4521 non-null   object\n",
      " 7   loan       4521 non-null   object\n",
      " 8   contact    4521 non-null   object\n",
      " 9   day        4521 non-null   int64 \n",
      " 10  month      4521 non-null   object\n",
      " 11  duration   4521 non-null   int64 \n",
      " 12  campaign   4521 non-null   int64 \n",
      " 13  pdays      4521 non-null   int64 \n",
      " 14  previous   4521 non-null   int64 \n",
      " 15  poutcome   4521 non-null   object\n",
      " 16  y          4521 non-null   int64 \n",
      "dtypes: int64(8), object(9)\n",
      "memory usage: 600.6+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Без категориальных признаков¶\n",
    "\n",
    "Попытаемся сначала просто проигнорировать категориальные признаки. Обучим случайный лес и посмотрим на ROC AUC на кросс-валидации и на отоженной выборке. Это будет наш бейзлайн.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_cat, y = df.loc[:, df.dtypes != 'object'].drop('y', axis=1), df['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_no_cat_part, df_no_cat_valid, y_train_part, y_valid = train_test_split(df_no_cat, y,\n",
    "                                                                            test_size=0.3, \n",
    "                                                                            stratify=y,\n",
    "                                                                            random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "forest = RandomForestClassifier(random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8495016786335677"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest, df_no_cat_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8631508998911164"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(df_no_cat_part, y_train_part)\n",
    "roc_auc_score(y_valid, forest.predict_proba(df_no_cat_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## LabelEncoder для категориальных признаков\n",
    "\n",
    "Сделаем то же самое, но попробуем закодировать категориальные признаки по-простому: с помощью LabelEncoder."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import LabelEncoder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_encoder = LabelEncoder()\n",
    "df_cat_label_enc = df.copy().drop('y', axis=1)\n",
    "for col in df.columns[df.dtypes == 'object']:\n",
    "    df_cat_label_enc[col] = label_encoder.fit_transform(df_cat_label_enc[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_label_enc_part, df_cat_label_enc_valid = train_test_split(df_cat_label_enc, test_size=.3, \n",
    "                                                    stratify=y, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8922975749958866"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest, df_cat_label_enc_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.908855334230022"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(df_cat_label_enc_part, y_train_part)\n",
    "roc_auc_score(y_valid, forest.predict_proba(df_cat_label_enc_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Бинаризация категориальных признаков (dummies, OHE)\n",
    "\n",
    "Теперь сделаем то, что обычно по умолчанию и делают – бинаризацию категориальных признаков. Dummy-признаки, One-Hot Encoding... с небольшими различиями это об одном же - для каждого значения каждого категориального признака завести свой бинарный признак.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_dummies = pd.get_dummies(df, columns=df.columns[df.dtypes == 'object']).drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_cat_dummies_part, df_cat_dummies_valid = train_test_split(df_cat_dummies, test_size=.3, \n",
    "                                                    stratify=y, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8988421716862304"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest, df_cat_dummies_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9172511155233887"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(df_cat_dummies_part, y_train_part)\n",
    "roc_auc_score(y_valid, forest.predict_proba(df_cat_dummies_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Попарные взаимодействия признаков¶\n",
    "\n",
    "Пока лес все еще лучше регрессии (хотя мы не тюнили гиперпараметры, но и не будем). Мы хотим идти дальше. Мощной техникой для работы с категориальными признаками будет учет попарных взаимодействий признаков (feature interactions). Построим попарные взаимодействия всех признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interact = df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features = df.columns[df.dtypes == 'object']\n",
    "for i, col1 in enumerate(cat_features):\n",
    "    for j, col2 in enumerate(cat_features[i + 1:]):\n",
    "        df_interact[col1 + '_' + col2] = df_interact[col1] + '_' + df_interact[col2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interact_cat_dummies = pd.get_dummies(df_interact, \n",
    "                                         columns=df_interact.columns[df_interact.dtypes == 'object']).\\\n",
    "                                                                                        drop('y', axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_interact_cat_dummies_part, df_interact_cat_dummies_valid = train_test_split(df_interact_cat_dummies, test_size=.3, \n",
    "                                                    stratify=y, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.833999698931206"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest, df_interact_cat_dummies_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8618112043382651"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(df_interact_cat_dummies_part, y_train_part)\n",
    "roc_auc_score(y_valid, forest.predict_proba(df_interact_cat_dummies_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "logit = LogisticRegression(random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8610739403953804"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(logit, df_interact_cat_dummies_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8530284591899913"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(df_interact_cat_dummies_part, y_train_part)\n",
    "roc_auc_score(y_valid, logit.predict_proba(df_interact_cat_dummies_valid)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "## Mean Target\n",
    "\n",
    "Теперь будем использовать технику кодирования категориальных признаков средним значением целевого признака. Это очень мощная техника, правда, надо умело ее использовать – легко переобучиться. Основная идея – для каждого значения категориального признака посчитать среднее значение целевого признака и заменить категориальный признак на посчитанные средние. Правда, считать средние надо на кросс-валидации, а то легко переобучиться."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, y = df.copy(), df['y']\n",
    "train_df_part, valid_df, y_train_part, y_valid = train_test_split(train_df.drop('y', axis=1), y, \n",
    "                                                                  test_size=.3, stratify=y, \n",
    "                                                                               random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [],
   "source": [
    "def mean_target_enc(train_df, y_train, valid_df, skf):\n",
    "        \n",
    "    glob_mean = y_train.mean()\n",
    "    train_df = pd.concat([train_df, pd.Series(y_train, name='y')], axis=1)\n",
    "    new_train_df = train_df.copy()\n",
    "    \n",
    "    cat_features = train_df.columns[train_df.dtypes == 'object'].tolist()    \n",
    "\n",
    "    for col in cat_features:\n",
    "        new_train_df[col + '_mean_target'] = [glob_mean for _ in range(new_train_df.shape[0])]\n",
    "\n",
    "    for train_idx, valid_idx in skf.split(train_df, y_train):\n",
    "        train_df_cv, valid_df_cv = train_df.iloc[train_idx, :], train_df.iloc[valid_idx, :]\n",
    "\n",
    "        for col in cat_features:\n",
    "            \n",
    "            means = valid_df_cv[col].map(train_df_cv.groupby(col)['y'].mean())\n",
    "            valid_df_cv[col + '_mean_target'] = means.fillna(glob_mean)\n",
    "            \n",
    "        new_train_df.iloc[valid_idx] = valid_df_cv\n",
    "    \n",
    "    new_train_df.drop(cat_features + ['y'], axis=1, inplace=True)\n",
    "    \n",
    "    for col in cat_features:\n",
    "        means = valid_df[col].map(train_df.groupby(col)['y'].mean())\n",
    "        valid_df[col + '_mean_target'] = means.fillna(glob_mean)\n",
    "        \n",
    "    valid_df.drop(train_df.columns[train_df.dtypes == 'object'], axis=1, inplace=True)\n",
    "    \n",
    "    return new_train_df, valid_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_target_part, valid_mean_target = mean_target_enc(train_df_part, y_train_part, valid_df, skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8813941498132323"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest, train_mean_target_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9108221780994471"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(train_mean_target_part, y_train_part)\n",
    "roc_auc_score(y_valid, forest.predict_proba(valid_mean_target)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Mean Target + попарные взаимодействия"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, y = df_interact.drop('y', axis=1).copy(), df_interact['y']\n",
    "train_df_part, valid_df, y_train_part, y_valid = train_test_split(df_interact_cat_dummies, y, \n",
    "                                                                  test_size=.3, stratify=y, \n",
    "                                                                               random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_mean_target_part, valid_mean_target = mean_target_enc(train_df_part, y_train_part, valid_df, skf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8341390438965304"
      ]
     },
     "execution_count": 92,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(forest, train_mean_target_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8618112043382651"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "forest.fit(train_mean_target_part, y_train_part)\n",
    "roc_auc_score(y_valid, forest.predict_proba(valid_mean_target)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8630756627889472"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cross_val_score(logit, train_mean_target_part, y_train_part, cv=skf, scoring='roc_auc'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8530284591899913"
      ]
     },
     "execution_count": 95,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logit.fit(train_mean_target_part, y_train_part)\n",
    "roc_auc_score(y_valid, logit.predict_proba(valid_mean_target)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Catboost\n",
    "\n",
    "В библиотеке Catboost, помимо всего прочего, реализована как раз техника кодирования категориальных значений средним значением целевого признака. Результаты получаются хорошими именно когда в данных много важных категориальных признаков."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from catboost import CatBoostClassifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "ctb = CatBoostClassifier(random_seed=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, y = df.drop('y', axis=1), df['y']\n",
    "train_df_part, valid_df, y_train_part, y_valid = train_test_split(train_df, y, \n",
    "                                                                  test_size=.3, stratify=y, \n",
    "                                                                  random_state=17)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [],
   "source": [
    "cat_features_idx = np.where(train_df_part.dtypes == 'object')[0].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 1min 32s, sys: 7.98 s, total: 1min 40s\n",
      "Wall time: 32 s\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "cv_scores = []\n",
    "for train_idx, test_idx in skf.split(train_df_part, y_train_part):\n",
    "    cv_train_df, cv_valid_df = train_df_part.iloc[train_idx, :], train_df_part.iloc[test_idx, :]\n",
    "    y_cv_train, y_cv_valid = y_train_part.iloc[train_idx], y_train_part.iloc[test_idx]\n",
    "    \n",
    "    ctb.fit(cv_train_df, y_cv_train,\n",
    "        cat_features=cat_features_idx, silent=True);\n",
    "    \n",
    "    cv_scores.append(roc_auc_score(y_cv_valid, ctb.predict_proba(cv_valid_df)[:, 1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9028648621209946"
      ]
     },
     "execution_count": 110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(cv_scores)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 20.8 s, sys: 1.53 s, total: 22.3 s\n",
      "Wall time: 7.04 s\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "<catboost.core.CatBoostClassifier at 0x7f73c0364250>"
      ]
     },
     "execution_count": 111,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%time\n",
    "ctb.fit(train_df_part, y_train_part,\n",
    "        cat_features=cat_features_idx,silent=True);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9190524989858878"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "roc_auc_score(y_valid, ctb.predict_proba(valid_df)[:, 1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## XGBoost"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 186,
   "metadata": {},
   "outputs": [],
   "source": [
    "import xgboost as xgb"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 187,
   "metadata": {},
   "outputs": [],
   "source": [
    "data_dmatrix = xgb.DMatrix(data=df_interact_cat_dummies_part, label=y_train_part)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 188,
   "metadata": {},
   "outputs": [],
   "source": [
    "params = {\"objective\":\"binary:logistic\"}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 189,
   "metadata": {},
   "outputs": [],
   "source": [
    "cv_results = xgb.cv(dtrain=data_dmatrix, params=params, nfold=5,\n",
    "                    num_boost_round=50, early_stopping_rounds=20, metrics=\"auc\", as_pandas=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 190,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>train-auc-mean</th>\n",
       "      <th>train-auc-std</th>\n",
       "      <th>test-auc-mean</th>\n",
       "      <th>test-auc-std</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.870920</td>\n",
       "      <td>0.015828</td>\n",
       "      <td>0.831096</td>\n",
       "      <td>0.029865</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.905074</td>\n",
       "      <td>0.013131</td>\n",
       "      <td>0.854364</td>\n",
       "      <td>0.019743</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.925652</td>\n",
       "      <td>0.006637</td>\n",
       "      <td>0.871439</td>\n",
       "      <td>0.014437</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.936959</td>\n",
       "      <td>0.005397</td>\n",
       "      <td>0.873073</td>\n",
       "      <td>0.017619</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.948667</td>\n",
       "      <td>0.003667</td>\n",
       "      <td>0.876884</td>\n",
       "      <td>0.016534</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   train-auc-mean  train-auc-std  test-auc-mean  test-auc-std\n",
       "0        0.870920       0.015828       0.831096      0.029865\n",
       "1        0.905074       0.013131       0.854364      0.019743\n",
       "2        0.925652       0.006637       0.871439      0.014437\n",
       "3        0.936959       0.005397       0.873073      0.017619\n",
       "4        0.948667       0.003667       0.876884      0.016534"
      ]
     },
     "execution_count": 190,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cv_results.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 191,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9096692926834475"
      ]
     },
     "execution_count": 191,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "xgb_class = xgb.XGBClassifier()\n",
    "xgb_class.fit(train_mean_target_part, y_train_part)\n",
    "roc_auc_score(y_valid, xgb_class.predict_proba(valid_mean_target)[:, 1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
