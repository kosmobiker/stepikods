{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 265,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import seaborn as sns\n",
    "import matplotlib as plt\n",
    "import re     \n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.linear_model import RidgeClassifier, LogisticRegression\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from tqdm import tqdm\n",
    "from sklearn.model_selection import GridSearchCV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 266,
   "metadata": {},
   "outputs": [],
   "source": [
    "SEED = 42"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 267,
   "metadata": {},
   "outputs": [],
   "source": [
    "# nltk.download('stopwords')\n",
    "# nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 268,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk import sent_tokenize, word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "from nltk.tokenize import TweetTokenizer\n",
    "from nltk.tokenize import sent_tokenize\n",
    "\n",
    "from nltk.corpus import stopwords\n",
    "\n",
    "from nltk.stem.porter import *\n",
    "import string"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***1*** if the tweet is describing a real disaster, and ***0*** otherwise"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/real_train.csv', encoding='utf-8').set_index('id')\n",
    "test = pd.read_csv('../../data/real_test.csv',encoding='utf-8').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train['target']\n",
    "train = train.drop(['location', 'keyword', 'target'], axis=1)\n",
    "test = test.drop(['location', 'keyword'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 271,
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = train.shape[0]\n",
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_URL(text):\n",
    "    url = re.compile(r'https?://\\S+|www\\.\\S+')\n",
    "    return url.sub(r'',text)\n",
    "\n",
    "def remove_emoji(text):\n",
    "    regrex_pattern = re.compile(pattern = \"[\"\n",
    "        u\"\\U0001F600-\\U0001F64F\"  # emoticons\n",
    "        u\"\\U0001F300-\\U0001F5FF\"  # symbols & pictographs\n",
    "        u\"\\U0001F680-\\U0001F6FF\"  # transport & map symbols\n",
    "        u\"\\U0001F1E0-\\U0001F1FF\"  # flags (iOS)\n",
    "                           \"]+\", flags = re.UNICODE)\n",
    "    return regrex_pattern.sub(r'',text)\n",
    "\n",
    "def decontracted(text):\n",
    "    text = re.sub(r\"won\\'t\", \"will not\", text)\n",
    "    text = re.sub(r\"can\\'t\", \"can not\", text)\n",
    "    text = re.sub(r\"n\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'re\", \" are\", text)\n",
    "    text = re.sub(r\"\\'s\", \" is\", text)\n",
    "    text = re.sub(r\"\\'d\", \" would\", text)\n",
    "    text = re.sub(r\"\\'ll\", \" will\", text)\n",
    "    text = re.sub(r\"\\'t\", \" not\", text)\n",
    "    text = re.sub(r\"\\'ve\", \" have\", text)\n",
    "    text = re.sub(r\"\\'m\", \" am\", text)\n",
    "    #also delete @ and #\n",
    "    text = re.sub(r\"[@+#+]\", \" \", text)\n",
    "    return text\n",
    "\n",
    "def remove_punct(text):\n",
    "    table = str.maketrans('','',string.punctuation)\n",
    "    return text.translate(table)\n",
    "\n",
    "cachedStopWords = stopwords.words(\"english\")\n",
    "\n",
    "def remove_stopwords(text):\n",
    "    text = ' '.join([word for word in text.split() if word not in cachedStopWords])\n",
    "    return text\n",
    "\n",
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 273,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function takes as input dataset and columns to process\n",
    "def clean_data(df, *variables):\n",
    "    for variable in variables:\n",
    "        df[variable] = df[variable].apply(lambda x : remove_URL(x))\n",
    "        df[variable] = df[variable].apply(lambda x : remove_emoji(x))\n",
    "        df[variable] = df[variable].apply(lambda x : decontracted(x))\n",
    "        df[variable] = df[variable].apply(lambda x : remove_punct(x))\n",
    "        df[variable] = df[variable].apply(lambda x : remove_stopwords(x))\n",
    "        df[variable] = df[variable].apply(lambda x : stemmer.stem(x))\n",
    "\n",
    "    return df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 274,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "                                                    text\n",
       "id                                                      \n",
       "1       our deeds reason earthquake may allah forgive us\n",
       "4                  forest fire near la ronge sask canada\n",
       "5      all residents asked ishelter place notified of...\n",
       "6      13000 people receive wildfires evacuation orde...\n",
       "7      just got sent photo ruby alaska smoke wildfire...\n",
       "...                                                  ...\n",
       "10861  earthquake safety los angeles ûò safety faste...\n",
       "10865  storm ri worse last hurricane my cityamp3other...\n",
       "10868                      green line derailment chicago\n",
       "10874           meg issues hazardous weather outlook hwo\n",
       "10875  cityofcalgary activated municipal emergency pl...\n",
       "\n",
       "[10876 rows x 1 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td>our deeds reason earthquake may allah forgive us</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>forest fire near la ronge sask canada</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td>all residents asked ishelter place notified of...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td>13000 people receive wildfires evacuation orde...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td>just got sent photo ruby alaska smoke wildfire...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10861</th>\n      <td>earthquake safety los angeles ûò safety faste...</td>\n    </tr>\n    <tr>\n      <th>10865</th>\n      <td>storm ri worse last hurricane my cityamp3other...</td>\n    </tr>\n    <tr>\n      <th>10868</th>\n      <td>green line derailment chicago</td>\n    </tr>\n    <tr>\n      <th>10874</th>\n      <td>meg issues hazardous weather outlook hwo</td>\n    </tr>\n    <tr>\n      <th>10875</th>\n      <td>cityofcalgary activated municipal emergency pl...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10876 rows × 1 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 274
    }
   ],
   "source": [
    "clean_data(df, 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = df[:idx]\n",
    "test = df[idx:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`max_df` is used for removing terms that appear too frequently, also known as \"corpus-specific stop words\". For example:\n",
    "\n",
    ">`max_df` = 0.50 means \"ignore terms that appear in more than 50% of the documents\".\n",
    ">`max_df` = 25 means \"ignore terms that appear in more than 25 documents\".\n",
    "\n",
    "The default `max_df` is 1.0, which means \"ignore terms that appear in more than 100% of the documents\". Thus, the default setting does not ignore any terms.\n",
    "\n",
    "`min_df` is used for removing terms that appear too infrequently. For example:\n",
    "\n",
    ">`min_df` = 0.01 means \"ignore terms that appear in less than 1% of the documents\".\n",
    ">`min_df` = 5 means \"ignore terms that appear in less than 5 documents\".\n",
    "\n",
    "The default `min_df` is 1, which means \"ignore terms that appear in less than 1 document\". Thus, the default setting does not ignore any terms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 276,
   "metadata": {},
   "outputs": [],
   "source": [
    "MAX_DF = 0.9\n",
    "MIN_COUNT = 5\n",
    "NGRAMS = (1, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 277,
   "metadata": {},
   "outputs": [],
   "source": [
    "TOKEN_RE = re.compile(r'[a-z]+|-?\\d*[-.,]?\\d+|\\S')\n",
    "\n",
    "def tokenize_text_simple_regex(txt, min_token_size=1):\n",
    "    txt = txt.lower()\n",
    "    all_tokens = TOKEN_RE.findall(txt)\n",
    "\n",
    "    return [token for token in all_tokens if len(token) >= min_token_size]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 278,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "TfidfVectorizer(max_df=0.9, min_df=5, ngram_range=(1, 2),\n",
       "                tokenizer=<function tokenize_text_simple_regex at 0x7f3d1134b0e0>)"
      ]
     },
     "metadata": {},
     "execution_count": 278
    }
   ],
   "source": [
    "vector = TfidfVectorizer(tokenizer=tokenize_text_simple_regex,\n",
    "                            min_df=MIN_COUNT, max_df=MAX_DF,\n",
    "                            ngram_range = NGRAMS)\n",
    "vector.fit(train['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 279,
   "metadata": {},
   "outputs": [],
   "source": [
    "#convert dataset into sparse matrix\n",
    "def vectorize_data(df, vectorizer):\n",
    "    return vectorizer.transform(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_vect = vectorize_data(train['text'], vector)\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(train_vect, y, \n",
    "                                            train_size=0.7, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 281,
   "metadata": {},
   "outputs": [],
   "source": [
    "clf1 = LogisticRegression(random_state=SEED).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 282,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score (train) 0.837\nF1 score (holdout) 0.748\n"
     ]
    }
   ],
   "source": [
    "print('F1 score (train) %.3f' % f1_score(y_train, clf1.predict(X_train)))\n",
    "print('F1 score (holdout) %.3f' % f1_score(y_holdout, clf1.predict(X_holdout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 283,
   "metadata": {},
   "outputs": [],
   "source": [
    "def submission(df, vectorizer, clf, name_submisson):\n",
    "    X_test = vectorize_data(df, vectorizer)\n",
    "    pred = clf.predict(X_test)\n",
    "    return pd.DataFrame(pred, index=test.index, columns=['target']).to_csv(name_submisson)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 284,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(test['text'], vector, clf1, 'submission.csv')\n",
    "#KAGGLE 0.79037"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 285,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = pd.read_csv('../../data/real_train.csv', encoding='utf-8').set_index('id')\n",
    "test = pd.read_csv('../../data/real_test.csv',encoding='utf-8').set_index('id')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 286,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "(0.33272034677525286, 0.3386454183266932)"
      ]
     },
     "metadata": {},
     "execution_count": 286
    }
   ],
   "source": [
    "train['location'].isna().sum()/len(train['location']), test['location'].isna().sum()/len(test['location'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 287,
   "metadata": {},
   "outputs": [],
   "source": [
    "train = train.drop(['keyword', 'target'], axis=1)\n",
    "test = test.drop(['keyword'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 288,
   "metadata": {},
   "outputs": [],
   "source": [
    "train['location'] = train['location'].fillna(' ')\n",
    "test['location'] = test['location'].fillna(' ')\n",
    "idx = train.shape[0]\n",
    "df = pd.concat([train, test])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 289,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "      location                                               text\n",
       "id                                                               \n",
       "1                our deeds reason earthquake may allah forgive us\n",
       "4                           forest fire near la ronge sask canada\n",
       "5               all residents asked ishelter place notified of...\n",
       "6               13000 people receive wildfires evacuation orde...\n",
       "7               just got sent photo ruby alaska smoke wildfire...\n",
       "...        ...                                                ...\n",
       "10861           earthquake safety los angeles ûò safety faste...\n",
       "10865           storm ri worse last hurricane my cityamp3other...\n",
       "10868                               green line derailment chicago\n",
       "10874                    meg issues hazardous weather outlook hwo\n",
       "10875           cityofcalgary activated municipal emergency pl...\n",
       "\n",
       "[10876 rows x 2 columns]"
      ],
      "text/html": "<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>location</th>\n      <th>text</th>\n    </tr>\n    <tr>\n      <th>id</th>\n      <th></th>\n      <th></th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>1</th>\n      <td></td>\n      <td>our deeds reason earthquake may allah forgive us</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td></td>\n      <td>forest fire near la ronge sask canada</td>\n    </tr>\n    <tr>\n      <th>5</th>\n      <td></td>\n      <td>all residents asked ishelter place notified of...</td>\n    </tr>\n    <tr>\n      <th>6</th>\n      <td></td>\n      <td>13000 people receive wildfires evacuation orde...</td>\n    </tr>\n    <tr>\n      <th>7</th>\n      <td></td>\n      <td>just got sent photo ruby alaska smoke wildfire...</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>10861</th>\n      <td></td>\n      <td>earthquake safety los angeles ûò safety faste...</td>\n    </tr>\n    <tr>\n      <th>10865</th>\n      <td></td>\n      <td>storm ri worse last hurricane my cityamp3other...</td>\n    </tr>\n    <tr>\n      <th>10868</th>\n      <td></td>\n      <td>green line derailment chicago</td>\n    </tr>\n    <tr>\n      <th>10874</th>\n      <td></td>\n      <td>meg issues hazardous weather outlook hwo</td>\n    </tr>\n    <tr>\n      <th>10875</th>\n      <td></td>\n      <td>cityofcalgary activated municipal emergency pl...</td>\n    </tr>\n  </tbody>\n</table>\n<p>10876 rows × 2 columns</p>\n</div>"
     },
     "metadata": {},
     "execution_count": 289
    }
   ],
   "source": [
    "clean_data(df, 'location', 'text')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 290,
   "metadata": {},
   "outputs": [],
   "source": [
    "df[\"text\"] = df[\"location\"] + \" \" + df[\"text\"]\n",
    "df = df.drop(['location'], axis=1)\n",
    "train = df[:idx]\n",
    "test = df[idx:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 291,
   "metadata": {},
   "outputs": [],
   "source": [
    "vector = TfidfVectorizer(tokenizer=tokenize_text_simple_regex,\n",
    "                            min_df=MIN_COUNT, max_df=MAX_DF,\n",
    "                            ngram_range = NGRAMS)\n",
    "vector.fit(train['text'])\n",
    "train_vect = vectorize_data(train['text'], vector)\n",
    "X_train, X_holdout, y_train, y_holdout = train_test_split(train_vect, y, \n",
    "                                            train_size=0.7, random_state=SEED)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 292,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score (train) 0.839\nF1 score (holdout) 0.747\n"
     ]
    }
   ],
   "source": [
    "clf2 = LogisticRegression(random_state=SEED).fit(X_train, y_train)\n",
    "print('F1 score (train) %.3f' % f1_score(y_train, clf2.predict(X_train)))\n",
    "print('F1 score (holdout) %.3f' % f1_score(y_holdout, clf2.predict(X_holdout)))"
   ]
  },
  {
   "source": [
    "Looks like additioanl feature with location does not impact on result\n",
    "\n",
    "\n",
    "F1 score (train) 0.840\n",
    "F1 score (holdout) 0.744"
   ],
   "cell_type": "markdown",
   "metadata": {}
  },
  {
   "cell_type": "code",
   "execution_count": 293,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score (train) 0.898\nF1 score (holdout) 0.734\n"
     ]
    }
   ],
   "source": [
    "clf3 = RidgeClassifier(random_state=SEED).fit(X_train, y_train)\n",
    "print('F1 score (train) %.3f' % f1_score(y_train, clf3.predict(X_train)))\n",
    "print('F1 score (holdout) %.3f' % f1_score(y_holdout, clf3.predict(X_holdout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 294,
   "metadata": {},
   "outputs": [
    {
     "output_type": "execute_result",
     "data": {
      "text/plain": [
       "{'alpha': 2}"
      ]
     },
     "metadata": {},
     "execution_count": 294
    }
   ],
   "source": [
    "params = {'alpha' : [0.001, 0.01, 0.1, 0.5, 1, 2, 3, 5, 7, 10]}\n",
    "grid = GridSearchCV(RidgeClassifier(random_state=SEED), param_grid=params, \n",
    "                    scoring='f1', cv=5).fit(X_train, y_train)\n",
    "best_clf = grid.best_estimator_\n",
    "grid.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 295,
   "metadata": {},
   "outputs": [
    {
     "output_type": "stream",
     "name": "stdout",
     "text": [
      "F1 score (train) 0.871\nF1 score (holdout) 0.741\n"
     ]
    }
   ],
   "source": [
    "print('F1 score (train) %.3f' % f1_score(y_train, best_clf.predict(X_train)))\n",
    "print('F1 score (holdout) %.3f' % f1_score(y_holdout, best_clf.predict(X_holdout)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "metadata": {},
   "outputs": [],
   "source": [
    "submission(test['text'], vector, best_clf, 'submission_2.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4-final"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}